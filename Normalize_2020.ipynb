{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import pickle\n",
    "from fbprophet import Prophet\n",
    "from fbprophet.plot import plot_plotly, plot_components_plotly\n",
    "# this might give errors if you don't have newer ver sof prophet. in that case, comment it out and load using pickle\n",
    "from fbprophet.serialize import model_to_json, model_from_json  \n",
    "import json\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to load pretraines model with pickle\n",
    "with open(\"pickled_model\", \"rb\") as f:\n",
    "   m = pickle.load(f)\n",
    "   \n",
    "# Code to load model with fb prophet serialize if that works\n",
    "# with open('serialized_model.json', 'r') as fin:\n",
    "#     m = model_from_json(json.load(fin))  # Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in data\n",
    "data = pd.read_csv(\"../input/msa-merged-data/msa_merged_data.csv\")\n",
    "data[\"BEGIN_DATE_GMT\"] = pd.to_datetime(data[\"BEGIN_DATE_GMT\"])\n",
    "\n",
    "# X-y split\n",
    "y = data[\"AIL_DEMAND\"]\n",
    "X = data.drop(columns = [\"AIL_DEMAND\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you'll probabs need to modify these quite abit, because we are using only the temperature of 2019 or whatever year, not the actual future temperture + the model is lagged \n",
    "\n",
    "# Functions to make FBProphet Datasets\n",
    "def make_prophet_df(X, y, regressors):\n",
    "    data = pd.DataFrame()\n",
    "    data[\"y\"] = y\n",
    "    data['ds'] = X[\"BEGIN_DATE_GMT\"]\n",
    "    for i in regressors:\n",
    "        data[i] = X[i]\n",
    "    return data\n",
    "\n",
    "def make_future_df(prophet_model, df_train, df_test, include_history = True):\n",
    "    # Creating the dataframe with datetime values to predict on (making predictions on train as well as the test set)\n",
    "    future_dates = prophet_model.make_future_dataframe(periods=len(df_test), freq='H', include_history= include_history)\n",
    "    # Adding regressors \n",
    "    if include_history:\n",
    "        future_dates = pd.merge(future_dates, (df_train.append(df_test)).drop('y', axis=1), on = 'ds')\n",
    "    else:\n",
    "        future_dates = pd.merge(future_dates, df_test.drop('y', axis=1), on = 'ds')\n",
    "\n",
    "    return future_dates\n",
    "\n",
    "# Making Lags\n",
    "# Choose Regressors\n",
    "X[\"Calgary_temp.1_hour_lag\"]=X[\"Calgary_temp\"].shift(1)\n",
    "X[\"Edmonton_temp.1_hour_lag\"]=X[\"Edmonton_temp\"].shift(1)\n",
    "X[\"FortMM_temp.1_hour_lag\"]=X[\"FortMM_Temp\"].shift(1)\n",
    "X[\"Lethbridge_temp.1_hour_lag\"]=X[\"Lethbridge_temp\"].shift(1)\n",
    "regressors = [\"Calgary_temp.1_hour_lag\",\"Edmonton_temp.1_hour_lag\",\"FortMM_temp.1_hour_lag\",\"Lethbridge_temp.1_hour_lag\",\"future 1\",\"WTI spot\",\"workingday\"]"
   ]
  }
 ]
}